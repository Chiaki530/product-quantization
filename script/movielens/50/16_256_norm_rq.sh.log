# load the base data ../data/movielens/movielens_base.fvecs, 
# load the queries ../data/movielens/movielens_query.fvecs, 
# load the ground truth ../data/movielens/50_movielens_product_groundtruth.ivecs
# ranking metric product
# NormPQ, percentiles: 256, quantize: Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 0,  residual average norm : 0.259373277425766 max norm: 0.7688350677490234 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 1,  residual average norm : 0.1901688128709793 max norm: 0.6341558694839478 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 2,  residual average norm : 0.14772361516952515 max norm: 0.5287684798240662 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 3,  residual average norm : 0.11792387813329697 max norm: 0.43812739849090576 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 4,  residual average norm : 0.09597765654325485 max norm: 0.3477039039134979 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 5,  residual average norm : 0.07936374098062515 max norm: 0.2535257041454315 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 6,  residual average norm : 0.0666583850979805 max norm: 0.20864169299602509 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 7,  residual average norm : 0.05669555068016052 max norm: 0.19279521703720093 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 8,  residual average norm : 0.04877842590212822 max norm: 0.15231212973594666 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 9,  residual average norm : 0.04232879355549812 max norm: 0.12760668992996216 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 10,  residual average norm : 0.03703445568680763 max norm: 0.11437027901411057 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 11,  residual average norm : 0.032600194215774536 max norm: 0.09401331841945648 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 12,  residual average norm : 0.028888637199997902 max norm: 0.07381602376699448 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 13,  residual average norm : 0.02572476677596569 max norm: 0.06648371368646622 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 14,  residual average norm : 0.023051995784044266 max norm: 0.06214984506368637 min norm: 0.0
# compress items
# sorting items
# searching!
expected items, overall time, avg recall, avg precision, avg error, avg items
1, 0, 0.02, 1.0, 0, 1
2, 0, 0.04, 1.0, 0, 2
4, 0, 0.08, 1.0, 0, 4
8, 0, 0.16, 1.0, 0, 8
16, 0, 0.31988, 0.999625, 0, 16
32, 0, 0.63792, 0.99675, 0, 32
64, 0, 0.98844, 0.77221875, 0, 64
128, 0, 0.9974599999999999, 0.3896328125, 0, 128
256, 0, 0.99858, 0.19503515625, 0, 256
512, 0, 0.9994799999999999, 0.09760546875, 0, 512
1024, 0, 1.0, 0.048828125, 0, 1024
2048, 0, 1.0, 0.0244140625, 0, 2048
4096, 0, 1.0, 0.01220703125, 0, 4096
8192, 0, 1.0, 0.006103515625, 0, 8192
16384, 0, 1.0, 0.004682963379226374, 0, 10677
