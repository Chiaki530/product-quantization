# load the base data ../data/movielens/movielens_base.fvecs, 
# load the queries ../data/movielens/movielens_query.fvecs, 
# load the ground truth ../data/movielens/50_movielens_product_groundtruth.ivecs
# ranking metric product
# Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 0,  residual average norm : 0.48049354553222656 max norm: 1.641195297241211 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 1,  residual average norm : 0.3543616533279419 max norm: 1.3287813663482666 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 2,  residual average norm : 0.27499914169311523 max norm: 1.1437712907791138 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 3,  residual average norm : 0.21920451521873474 max norm: 0.7764960527420044 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 4,  residual average norm : 0.1781606823205948 max norm: 0.6409226655960083 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 5,  residual average norm : 0.14702843129634857 max norm: 0.5139897465705872 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 6,  residual average norm : 0.12333574146032333 max norm: 0.4145239591598511 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 7,  residual average norm : 0.10495049506425858 max norm: 0.35840126872062683 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 8,  residual average norm : 0.09008769690990448 max norm: 0.2767906188964844 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 9,  residual average norm : 0.07810565829277039 max norm: 0.2501083016395569 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 10,  residual average norm : 0.06827462464570999 max norm: 0.22861266136169434 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 11,  residual average norm : 0.060074616223573685 max norm: 0.16145651042461395 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 12,  residual average norm : 0.05320856347680092 max norm: 0.14965100586414337 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 13,  residual average norm : 0.04736120626330376 max norm: 0.12488552927970886 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 14,  residual average norm : 0.04235115647315979 max norm: 0.11046471446752548 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 15,  residual average norm : 0.03801824152469635 max norm: 0.09744270145893097 min norm: 0.0
# compress items
# sorting items
# searching!
expected items, overall time, avg recall, avg precision, avg error, avg items
1, 0, 0.02, 1.0, 0, 1
2, 0, 0.04, 1.0, 0, 2
4, 0, 0.08, 1.0, 0, 4
8, 0, 0.16, 1.0, 0, 8
16, 0, 0.32, 1.0, 0, 16
32, 0, 0.64, 1.0, 0, 32
64, 0, 0.99914, 0.780578125, 0, 64
128, 0, 1.0, 0.390625, 0, 128
256, 0, 1.0, 0.1953125, 0, 256
512, 0, 1.0, 0.09765625, 0, 512
1024, 0, 1.0, 0.048828125, 0, 1024
2048, 0, 1.0, 0.0244140625, 0, 2048
4096, 0, 1.0, 0.01220703125, 0, 4096
8192, 0, 1.0, 0.006103515625, 0, 8192
16384, 0, 1.0, 0.004682963379226374, 0, 10677
