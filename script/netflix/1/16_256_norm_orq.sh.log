# load the base data ../data/netflix/netflix_base.fvecs, 
# load the queries ../data/netflix/netflix_query.fvecs, 
# load the ground truth ../data/netflix/1_netflix_product_groundtruth.ivecs
# ranking metric product
# NormPQ, percentiles: 256, quantize: ORQ, RQ : [Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>],  M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 0,  residual average norm : 0.2225666642189026 max norm: 0.6863847970962524 min norm: 0.02290729433298111
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 1,  residual average norm : 0.15743471682071686 max norm: 0.5638503432273865 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 2,  residual average norm : 0.12089712172746658 max norm: 0.45613011717796326 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 3,  residual average norm : 0.09658940136432648 max norm: 0.4336833655834198 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 4,  residual average norm : 0.0793064534664154 max norm: 0.3539961576461792 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 5,  residual average norm : 0.06629946082830429 max norm: 0.30438679456710815 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 6,  residual average norm : 0.056244853883981705 max norm: 0.21801705658435822 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 7,  residual average norm : 0.04842502623796463 max norm: 0.18750549852848053 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 8,  residual average norm : 0.04217510297894478 max norm: 0.15969423949718475 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 9,  residual average norm : 0.03704327717423439 max norm: 0.14582127332687378 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 10,  residual average norm : 0.0329165942966938 max norm: 0.1293327808380127 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 11,  residual average norm : 0.02945711836218834 max norm: 0.12235211580991745 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 12,  residual average norm : 0.02655971609055996 max norm: 0.08785806596279144 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 13,  residual average norm : 0.024102745577692986 max norm: 0.07977849990129471 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 14,  residual average norm : 0.02200024202466011 max norm: 0.06828555464744568 min norm: 0.0
# compress items
# sorting items
# searching!
expected items, overall time, avg recall, avg precision, avg error, avg items
1, 0, 0.636, 0.636, 0, 1
2, 0, 0.829, 0.4145, 0, 2
4, 0, 0.969, 0.24225, 0, 4
8, 0, 0.998, 0.12475, 0, 8
16, 0, 1.0, 0.0625, 0, 16
32, 0, 1.0, 0.03125, 0, 32
64, 0, 1.0, 0.015625, 0, 64
128, 0, 1.0, 0.0078125, 0, 128
256, 0, 1.0, 0.00390625, 0, 256
512, 0, 1.0, 0.001953125, 0, 512
1024, 0, 1.0, 0.0009765625, 0, 1024
2048, 0, 1.0, 0.00048828125, 0, 2048
4096, 0, 1.0, 0.000244140625, 0, 4096
8192, 0, 1.0, 0.0001220703125, 0, 8192
16384, 0, 1.0, 6.103515625e-05, 0, 16384
32768, 0, 1.0, 5.627462014631401e-05, 0, 17770
