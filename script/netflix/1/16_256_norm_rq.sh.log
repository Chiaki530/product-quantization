# load the base data ../data/netflix/netflix_base.fvecs, 
# load the queries ../data/netflix/netflix_query.fvecs, 
# load the ground truth ../data/netflix/1_netflix_product_groundtruth.ivecs
# ranking metric product
# NormPQ, percentiles: 256, quantize: Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>Subspace PQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 0,  residual average norm : 0.22268709540367126 max norm: 0.6974430680274963 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 1,  residual average norm : 0.15734504163265228 max norm: 0.5736045837402344 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 2,  residual average norm : 0.12098390609025955 max norm: 0.46967190504074097 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 3,  residual average norm : 0.0967310220003128 max norm: 0.3869956135749817 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 4,  residual average norm : 0.07930317521095276 max norm: 0.34605279564857483 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 5,  residual average norm : 0.06624303758144379 max norm: 0.3310319781303406 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 6,  residual average norm : 0.056285638362169266 max norm: 0.2378353327512741 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 7,  residual average norm : 0.04850083589553833 max norm: 0.22018283605575562 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 8,  residual average norm : 0.04221625626087189 max norm: 0.1621776968240738 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 9,  residual average norm : 0.03719855099916458 max norm: 0.13510443270206451 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 10,  residual average norm : 0.033030908554792404 max norm: 0.12275312095880508 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 11,  residual average norm : 0.029613202437758446 max norm: 0.1161857470870018 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 12,  residual average norm : 0.02670658938586712 max norm: 0.0889936313033104 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 13,  residual average norm : 0.024241473525762558 max norm: 0.0754447728395462 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 300
# layer: 14,  residual average norm : 0.022111978381872177 max norm: 0.0710005834698677 min norm: 0.0
# compress items
# sorting items
# searching!
expected items, overall time, avg recall, avg precision, avg error, avg items
1, 0, 0.721, 0.721, 0, 1
2, 0, 0.894, 0.447, 0, 2
4, 0, 0.972, 0.243, 0, 4
8, 0, 0.997, 0.124625, 0, 8
16, 0, 1.0, 0.0625, 0, 16
32, 0, 1.0, 0.03125, 0, 32
64, 0, 1.0, 0.015625, 0, 64
128, 0, 1.0, 0.0078125, 0, 128
256, 0, 1.0, 0.00390625, 0, 256
512, 0, 1.0, 0.001953125, 0, 512
1024, 0, 1.0, 0.0009765625, 0, 1024
2048, 0, 1.0, 0.00048828125, 0, 2048
4096, 0, 1.0, 0.000244140625, 0, 4096
8192, 0, 1.0, 0.0001220703125, 0, 8192
16384, 0, 1.0, 6.103515625e-05, 0, 16384
32768, 0, 1.0, 5.627462014631401e-05, 0, 17770
