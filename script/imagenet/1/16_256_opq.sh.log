# load the base data ../data/imagenet/imagenet_base.fvecs, 
# load the queries ../data/imagenet/imagenet_query.fvecs, 
# load the ground truth ../data/imagenet/1_imagenet_product_groundtruth.ivecs
# ranking metric product
# ORQ, RQ : [Subspace PQ, M: 16, Ks : 256, code_dtype: <class 'numpy.uint8'>],  M: 16, Ks : 256, code_dtype: <class 'numpy.uint8'>
#    Training the subspace: 0 / 16, 0 -> 10
#    Training the subspace: 1 / 16, 10 -> 20
#    Training the subspace: 2 / 16, 20 -> 30
#    Training the subspace: 3 / 16, 30 -> 40
#    Training the subspace: 4 / 16, 40 -> 50
#    Training the subspace: 5 / 16, 50 -> 60
#    Training the subspace: 6 / 16, 60 -> 69
#    Training the subspace: 7 / 16, 69 -> 78
#    Training the subspace: 8 / 16, 78 -> 87
#    Training the subspace: 9 / 16, 87 -> 96
#    Training the subspace: 10 / 16, 96 -> 105
#    Training the subspace: 11 / 16, 105 -> 114
#    Training the subspace: 12 / 16, 114 -> 123
#    Training the subspace: 13 / 16, 123 -> 132
#    Training the subspace: 14 / 16, 132 -> 141
#    Training the subspace: 15 / 16, 141 -> 150
# layer: 0,  residual average norm : 0.09880247712135315 max norm: 0.6210853457450867 min norm: 0.023860471323132515
# layer: 0,  residual average norm : 0.09880247712135315 max norm: 0.6210854053497314 min norm: 0.023860488086938858
# compress items
# sorting items
# searching!
expected items, overall time, avg recall, avg precision, avg error, avg items
1, 0, 0.12, 0.12, 0, 1
2, 0, 0.199, 0.0995, 0, 2
4, 0, 0.285, 0.07125, 0, 4
8, 0, 0.389, 0.048625, 0, 8
16, 0, 0.494, 0.030875, 0, 16
32, 0, 0.611, 0.01909375, 0, 32
64, 0, 0.735, 0.011484375, 0, 64
128, 0, 0.829, 0.0064765625, 0, 128
256, 0, 0.899, 0.00351171875, 0, 256
512, 0, 0.947, 0.001849609375, 0, 512
1024, 0, 0.971, 0.0009482421875, 0, 1024
2048, 0, 0.982, 0.0004794921875, 0, 2048
4096, 0, 0.997, 0.000243408203125, 0, 4096
8192, 0, 0.998, 0.000121826171875, 0, 8192
16384, 0, 0.998, 6.09130859375e-05, 0, 16384
32768, 0, 0.999, 3.0487060546875e-05, 0, 32768
65536, 0, 1.0, 1.52587890625e-05, 0, 65536
131072, 0, 1.0, 7.62939453125e-06, 0, 131072
262144, 0, 1.0, 3.814697265625e-06, 0, 262144
524288, 0, 1.0, 1.9073486328125e-06, 0, 524288
1048576, 0, 1.0, 9.5367431640625e-07, 0, 1048576
2097152, 0, 1.0, 4.76837158203125e-07, 0, 2097152
4194304, 0, 1.0, 4.272823178185699e-07, 0, 2340373
