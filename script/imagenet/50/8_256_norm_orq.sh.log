# load the base data ../data/imagenet/imagenet_base.fvecs, 
# load the queries ../data/imagenet/imagenet_query.fvecs, 
# load the ground truth ../data/imagenet/20_imagenet_product_groundtruth.ivecs
# ranking metric product
# NormPQ, percentiles: 256, quantize: OPQ, M: 1, Ks : 256, code_dtype: <class 'numpy.uint8'>
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 0,  residual average norm : 0.6845022439956665 max norm: 1.0284247398376465 min norm: 0.1118190586566925
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 1,  residual average norm : 0.5999408960342407 max norm: 0.962308943271637 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 2,  residual average norm : 0.5484230518341064 max norm: 0.9137887954711914 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 3,  residual average norm : 0.5099238157272339 max norm: 0.8881378173828125 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 4,  residual average norm : 0.47904086112976074 max norm: 0.8539683818817139 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 5,  residual average norm : 0.4540175795555115 max norm: 0.8223704695701599 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 6,  residual average norm : 0.43100982904434204 max norm: 0.7859500050544739 min norm: 0.0
# compress items
# sorting items
# searching!
expected items, overall time, avg recall, avg precision, avg error, avg items
1, 0, 0.0306, 0.612, 0, 1
2, 0, 0.0586, 0.586, 0, 2
4, 0, 0.10915, 0.54575, 0, 4
8, 0, 0.193, 0.48250000000000004, 0, 8
16, 0, 0.3215, 0.401875, 0, 16
32, 0, 0.4909, 0.3068125, 0, 32
64, 0, 0.66585, 0.208078125, 0, 64
128, 0, 0.8151999999999999, 0.127375, 0, 128
256, 0, 0.9128000000000001, 0.0713125, 0, 256
512, 0, 0.9651, 0.03769921875, 0, 512
1024, 0, 0.9874, 0.01928515625, 0, 1024
2048, 0, 0.9960000000000001, 0.0097265625, 0, 2048
4096, 0, 0.9984, 0.004875, 0, 4096
8192, 0, 0.99925, 0.0024395751953125, 0, 8192
16384, 0, 0.99975, 0.00122039794921875, 0, 16384
32768, 0, 0.9999, 0.00061029052734375, 0, 32768
65536, 0, 0.9999499999999999, 0.0003051605224609375, 0, 65536
131072, 0, 0.9999499999999999, 0.00015258026123046874, 0, 131072
262144, 0, 0.9999499999999999, 7.629013061523437e-05, 0, 262144
524288, 0, 0.9999499999999999, 3.8145065307617185e-05, 0, 524288
1048576, 0, 0.9999499999999999, 1.9072532653808593e-05, 0, 1048576
2097152, 0, 1.0, 9.5367431640625e-06, 0, 2097152
4194304, 0, 1.0, 8.545646356371399e-06, 0, 2340373
